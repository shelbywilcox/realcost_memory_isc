{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nilearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\shelby\\anaconda3\\envs\\shelby_neuroimaging\\lib\\site-packages\\nilearn\\datasets\\__init__.py:96: FutureWarning: Fetchers from the nilearn.datasets module will be updated in version 0.9 to return python strings instead of bytes and Pandas dataframes instead of Numpy arrays.\n",
      "  \"Numpy arrays.\", FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "import glob \n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import sys, os, nilearn\n",
    "from nilearn import input_data, datasets\n",
    "from nilearn import plotting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../data_realcost/masker/allcombined.nii\n",
      "NiftiLabelsMasker(detrend=True, high_pass=0.01,\n",
      "                  labels_img='../data_realcost/masker/allcombined.nii',\n",
      "                  low_pass=0.12, standardize=True, t_r=2.0)\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "Data given cannot be loaded because it is not compatible with nibabel format:\nallcombined.nii',\n...",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_17440/2931640162.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      8\u001b[0m                                              low_pass    = 0.12 );\n\u001b[0;32m      9\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mall293_masker\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 10\u001b[1;33m \u001b[0mnilearn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mplotting\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mplot_roi\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mall293_masker\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtitle\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'Our mask'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m;\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     11\u001b[0m \u001b[1;31m#all293_masker.fit('D:/SHELBY_DATA/REALCOST/data/00_func_data/niis')\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\shelby\\anaconda3\\envs\\shelby_neuroimaging\\lib\\site-packages\\nilearn\\plotting\\img_plotting.py\u001b[0m in \u001b[0;36mplot_roi\u001b[1;34m(roi_img, bg_img, cut_coords, output_file, display_mode, figure, axes, title, annotate, draw_cross, black_bg, threshold, alpha, cmap, dim, vmin, vmax, resampling_interpolation, view_type, linewidths, **kwargs)\u001b[0m\n\u001b[0;32m    686\u001b[0m         \u001b[0mthreshold\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mthreshold\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbg_vmin\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mbg_vmin\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbg_vmax\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mbg_vmax\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    687\u001b[0m         \u001b[0mresampling_interpolation\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mresampling_interpolation\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 688\u001b[1;33m         alpha=alpha, cmap=cmap, vmin=vmin, vmax=vmax, **kwargs)\n\u001b[0m\u001b[0;32m    689\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    690\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mview_type\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'contours'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\shelby\\anaconda3\\envs\\shelby_neuroimaging\\lib\\site-packages\\nilearn\\plotting\\img_plotting.py\u001b[0m in \u001b[0;36m_plot_img_with_bg\u001b[1;34m(img, bg_img, cut_coords, output_file, display_mode, colorbar, figure, axes, title, threshold, annotate, draw_cross, black_bg, vmin, vmax, bg_vmin, bg_vmax, interpolation, display_factory, cbar_vmin, cbar_vmax, brain_color, decimals, **kwargs)\u001b[0m\n\u001b[0;32m    168\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    169\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mimg\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mFalse\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mimg\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 170\u001b[1;33m         \u001b[0mimg\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_utils\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcheck_niimg_3d\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'auto'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    171\u001b[0m         \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_safe_get_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mensure_finite\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    172\u001b[0m         \u001b[0maffine\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mimg\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0maffine\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\shelby\\anaconda3\\envs\\shelby_neuroimaging\\lib\\site-packages\\nilearn\\_utils\\niimg_conversions.py\u001b[0m in \u001b[0;36mcheck_niimg_3d\u001b[1;34m(niimg, dtype)\u001b[0m\n\u001b[0;32m    336\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    337\u001b[0m     \"\"\"\n\u001b[1;32m--> 338\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mcheck_niimg\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mniimg\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mensure_ndim\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    339\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    340\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\shelby\\anaconda3\\envs\\shelby_neuroimaging\\lib\\site-packages\\nilearn\\_utils\\niimg_conversions.py\u001b[0m in \u001b[0;36mcheck_niimg\u001b[1;34m(niimg, ensure_ndim, atleast_4d, dtype, return_iterator, wildcards)\u001b[0m\n\u001b[0;32m    281\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    282\u001b[0m     \u001b[1;31m# Otherwise, it should be a filename or a SpatialImage, we load it\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 283\u001b[1;33m     \u001b[0mniimg\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mload_niimg\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mniimg\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    284\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    285\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mensure_ndim\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m3\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mniimg\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m4\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mniimg\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\shelby\\anaconda3\\envs\\shelby_neuroimaging\\lib\\site-packages\\nilearn\\_utils\\niimg.py\u001b[0m in \u001b[0;36mload_niimg\u001b[1;34m(niimg, dtype)\u001b[0m\n\u001b[0;32m    130\u001b[0m         raise TypeError(\"Data given cannot be loaded because it is\"\n\u001b[0;32m    131\u001b[0m                         \u001b[1;34m\" not compatible with nibabel format:\\n\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 132\u001b[1;33m                         + _repr_niimgs(niimg, shorten=True))\n\u001b[0m\u001b[0;32m    133\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    134\u001b[0m     \u001b[0mdtype\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_get_target_dtype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_get_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mniimg\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: Data given cannot be loaded because it is not compatible with nibabel format:\nallcombined.nii',\n..."
     ]
    }
   ],
   "source": [
    "combined  = '../data_realcost/masker/allcombined.nii'\n",
    "print(combined)\n",
    "all293_masker = input_data.NiftiLabelsMasker(combined, \n",
    "                                             detrend     = True, \n",
    "                                             standardize = True,\n",
    "                                             high_pass   = 0.01, \n",
    "                                             t_r         = 2.0, \n",
    "                                             low_pass    = 0.12 );\n",
    "print(all293_masker)\n",
    "nilearn.plotting.plot_roi(all293_masker, title='Our mask');\n",
    "#all293_masker.fit('D:/SHELBY_DATA/REALCOST/data/00_func_data/niis')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def choose_mask(file,detrnd=\"True\",stndrd=\"True\",hp=\"0.01\",tr=\"2.0\",lp=\"0.12\"):\n",
    "    mask  = '../data_realcost/masker/'+ file +'.nii'\n",
    "    \n",
    "    masker = input_data.NiftiLabelsMasker(mask, \n",
    "                                             detrend     = detrnd, \n",
    "                                             standardize = stndrd,\n",
    "                                             high_pass   = hp, \n",
    "                                             t_r         = tr, \n",
    "                                             low_pass    = lp );\n",
    "    \n",
    "    plot = nilearn.plotting.plot_roi(masker, title='Our mask');\n",
    "    \n",
    "    return masker, plot\n",
    "\n",
    "choose_mask()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "._PSA017_swrealcost_run01_st.nii\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "40"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_data_path = 'D:/SHELBY_DATA/REALCOST/data/00_func_data/niis'\n",
    "motion_data_path = 'D:/SHELBY_DATA/REALCOST/data/00_func_data/motion/'\n",
    "subjs = [f for f in os.listdir(raw_data_path)]\n",
    "print(subjs[35])\n",
    "subjs.remove(subjs[35])\n",
    "n_subjs = len(subjs)\n",
    "n_subjs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PSA038_swrealcost_run01_st.nii\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "File not found: '../data_realcost/masker/allcombined.nii'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_16776/420429270.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      4\u001b[0m     \u001b[0mmotion_file\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmotion_data_path\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mcurr_subject\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m'_rp_realcost_run01_st.txt'\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m     \u001b[0mtime_series\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mall293_masker\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata_file\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mconfounds\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmotion_file\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      7\u001b[0m     \u001b[0moutname\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'../data_realcost/'\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mcurr_subject\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m'_shen_extracted_hp001_lp012_ltr_stand.npy'\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m     \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msave\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moutname\u001b[0m \u001b[1;33m,\u001b[0m \u001b[0mtime_series\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\shelby\\anaconda3\\envs\\shelby_neuroimaging\\lib\\site-packages\\nilearn\\input_data\\nifti_labels_masker.py\u001b[0m in \u001b[0;36mfit_transform\u001b[1;34m(self, imgs, confounds, sample_mask)\u001b[0m\n\u001b[0;32m    389\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    390\u001b[0m         \"\"\"\n\u001b[1;32m--> 391\u001b[1;33m         return self.fit().transform(imgs, confounds=confounds,\n\u001b[0m\u001b[0;32m    392\u001b[0m                                     sample_mask=sample_mask)\n\u001b[0;32m    393\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\shelby\\anaconda3\\envs\\shelby_neuroimaging\\lib\\site-packages\\nilearn\\input_data\\nifti_labels_masker.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, imgs, y)\u001b[0m\n\u001b[0;32m    328\u001b[0m                                        shorten=(not self.verbose)),\n\u001b[0;32m    329\u001b[0m                    verbose=self.verbose)\n\u001b[1;32m--> 330\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlabels_img_\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_utils\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcheck_niimg_3d\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlabels_img\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    331\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmask_img\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    332\u001b[0m             logger.log(\"loading data from %s\" %\n",
      "\u001b[1;32mc:\\users\\shelby\\anaconda3\\envs\\shelby_neuroimaging\\lib\\site-packages\\nilearn\\_utils\\niimg_conversions.py\u001b[0m in \u001b[0;36mcheck_niimg_3d\u001b[1;34m(niimg, dtype)\u001b[0m\n\u001b[0;32m    336\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    337\u001b[0m     \"\"\"\n\u001b[1;32m--> 338\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mcheck_niimg\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mniimg\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mensure_ndim\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    339\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    340\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\shelby\\anaconda3\\envs\\shelby_neuroimaging\\lib\\site-packages\\nilearn\\_utils\\niimg_conversions.py\u001b[0m in \u001b[0;36mcheck_niimg\u001b[1;34m(niimg, ensure_ndim, atleast_4d, dtype, return_iterator, wildcards)\u001b[0m\n\u001b[0;32m    269\u001b[0m                 \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmessage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    270\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 271\u001b[1;33m                 \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"File not found: '%s'\"\u001b[0m \u001b[1;33m%\u001b[0m \u001b[0mniimg\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    272\u001b[0m         \u001b[1;32melif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexists\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mniimg\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    273\u001b[0m             \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"File not found: '%s'\"\u001b[0m \u001b[1;33m%\u001b[0m \u001b[0mniimg\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: File not found: '../data_realcost/masker/allcombined.nii'"
     ]
    }
   ],
   "source": [
    "for curr_subject in subjs:\n",
    "    print(curr_subject)\n",
    "    data_file =  raw_data_path + curr_subject \n",
    "    motion_file = motion_data_path + curr_subject + '_rp_realcost_run01_st.txt'\n",
    "    \n",
    "    time_series = all293_masker.fit_transform(data_file, confounds = motion_file)\n",
    "    outname = '../data_realcost/' + curr_subject + '_shen_extracted_hp001_lp012_ltr_stand.npy'\n",
    "    np.save(outname , time_series)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
